package handsfree;

import java.io.IOException;

import edu.cmu.sphinx.api.Configuration;
import edu.cmu.sphinx.api.LiveSpeechRecognizer;
import edu.cmu.sphinx.api.SpeechResult;

public class SpeechThread extends Thread {
    private static String speech;
    public void run() {
        Configuration configuration = new Configuration();

        // Set path to acoustic model.
        configuration
                .setAcousticModelPath("resource:/edu/cmu/sphinx/models/en-us/en-us");
        // Set path to dictionary.
        configuration
                .setDictionaryPath("resource:/edu/cmu/sphinx/models/en-us/cmudict-en-us.dict");
        // Set language model.
        configuration
                .setLanguageModelPath("resource:/edu/cmu/sphinx/models/en-us/en-us.lm.dmp");

        try {
            System.out.println("starting recognizer");
            LiveSpeechRecognizer recognizer = new LiveSpeechRecognizer(
                    configuration);
            // Start recognition process pruning previously cached data.
            System.out.println("starting result loop");
            recognizer.startRecognition(true);
            while (true) {
                SpeechResult result = recognizer.getResult();
                System.out.println(result.getHypothesis());
            }
        } catch (IOException e) {
            System.err.println(e);
        }
        // Pause recognition process. It can be resumed then with
        // startRecognition(false).
        // recognizer.stopRecognition();
    }
}
