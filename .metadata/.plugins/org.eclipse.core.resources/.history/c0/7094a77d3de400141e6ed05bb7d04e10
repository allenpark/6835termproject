package handsfree;

import java.io.IOException;

import edu.cmu.sphinx.api.Configuration;
import edu.cmu.sphinx.api.LiveSpeechRecognizer;
import edu.cmu.sphinx.api.SpeechResult;

public class SpeechThread extends Thread {
    private String speech;

    public SpeechThread() {
        this.speech = null;
    }

    public void run() {
        Configuration configuration = new Configuration();

        // Set path to acoustic model.
        configuration
                .setAcousticModelPath("resource:/edu/cmu/sphinx/models/en-us/en-us");
        // Set path to dictionary.
        configuration
                .setDictionaryPath("resource:/edu/cmu/sphinx/models/en-us/cmudict-en-us.dict");
        // Set language model.
        configuration
                .setLanguageModelPath("resource:/edu/cmu/sphinx/models/en-us/en-us.lm.dmp");

        LiveSpeechRecognizer recognizer = null;
        try {
            recognizer = new LiveSpeechRecognizer(configuration);
        } catch (IOException e) {
            // TODO Auto-generated catch block
            e.printStackTrace();
        }
        // Start recognition process pruning previously cached data.
        recognizer.startRecognition(true);
        while (true) {
            SpeechResult result = recognizer.getResult();
            synchronized (this.speech) {
                this.speech = result.getHypothesis();
            }
        }
        // Pause recognition process. It can be resumed then with
        // startRecognition(false).
        // recognizer.stopRecognition();
    }

    public String getSpeech() {
        if (speech == null) {
            return null;
        }
        synchronized (this.speech) {
            return this.speech;
        }
    }
}
